---
layout: default
title: Domains
nav_order: 20
has_children: true
---

# Domain-Specific Evaluation

When it comes to domain-specific evaluation, there is a growing list of leaderboards, benchmarks, and related datasets. 

For example, the [Galileo Agent Leaderboard v2](https://huggingface.co/spaces/galileo-ai/agent-leaderboard){:target="galileo-lb"} from [Galileo AI](https://galileo.ai){:target="galileo"} evaluates the performance of LLM agents across several business domains. Their [dataset](https://huggingface.co/datasets/galileo-ai/agent-leaderboard-v2){:target="galileo-data"} could be useful for building custom domain-specific evaluations.

The AI Alliance [Open Trusted Data Initiative](https://the-ai-alliance.github.io/open-trusted-data-initiative/){:target="otdi"} is [cataloging](https://the-ai-alliance.github.io/open-trusted-data-initiative/catalog/){:target="otdi"} open-use datasets and making it relatively easy to find datasets relevant for particular domains, modalities, human languages, etc. For example, [this link](https://the-ai-alliance.github.io/open-trusted-data-initiative/catalog/domain/#finance){:target="otdi-finance"} takes you to a table for open datasets hosted at Hugging Face pertaining to finance topics.

# The Domains We Are Studying

We are studying the domains analyzed in the "child" pages listed below. At this stage, we are gathering information about common, desirable applications of Generative AI (GenAI) in these domains. Subsequent work will include documenting representative _use cases_, followed by an analysis of important risks for each application and use case.

Each domain page also lists the contributors for that domain. For the overall project maintainers, see [About Us]({{site.baseurl}}/about).
